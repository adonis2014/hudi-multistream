hoodie.upsert.shuffle.parallelism=2
hoodie.insert.shuffle.parallelism=2
hoodie.bulkinsert.shuffle.parallelism=2

# Key fields, for kafka example
hoodie.datasource.write.recordkey.field=_row_key
hoodie.datasource.write.partitionpath.field=
hoodie.datasource.write.precombine.field=_extend_ts_ms
hoodie.datasource.write.keygenerator.class=org.apache.hudi.keygen.NonpartitionedKeyGenerator
hoodie.datasource.hive_sync.use_jdbc=false
# Kafka Source topic
hoodie.deltastreamer.source.kafka.topic=bigdata-mysql.bigdata.test_time

# Kafka props
# The kafka cluster we want to ingest from
bootstrap.servers=kafka-node:9092
schema.registry.url=http://schema-registry-node:8081
auto.offset.reset=earliest
group.id=hoodie-delta-streamer
key.deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
value.deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer

hoodie.deltastreamer.schemaprovider.registry.url=http://schema-registry-node:8081/subjects/bigdata-mysql.bigdata.test_time-value/versions/latest

hoodie.datasource.hive_sync.database=bigdata
hoodie.datasource.hive_sync.table=test_time
hoodie.datasource.hive_sync.username=xxxx
hoodie.datasource.hive_sync.password=xxxx
hoodie.datasource.hive_sync.jdbcurl=jdbc:hive2://hive-node:10000
hoodie.datasource.hive_sync.partition_extractor_class=org.apache.hudi.hive.NonPartitionedExtractor

# \u5916\u7F6E timeline server
hoodie.embed.timeline.server=false
hoodie.filesystem.view.remote.host=xxxx
hoodie.filesystem.view.remote.port=26754
hoodie.filesystem.view.type=REMOTE_ONLY
